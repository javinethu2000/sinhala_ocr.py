#!/usr/bin/env python3
"""
Complete Sinhala Character Recognition Training System
Training ALL Sinhala Unicode characters for comprehensive OCR.
"""

import os
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import json
from sinhala_ocr import make_dataset_arrays

# COMPLETE SINHALA CHARACTER SET - ALL UNICODE CHARACTERS
COMPLETE_SINHALA_CHARS = [
    # Independent vowels (18)
    '‡∂Ö', '‡∂Ü', '‡∂á', '‡∂à', '‡∂â', '‡∂ä', '‡∂ã', '‡∂å', '‡∂ç', '‡∂é', '‡∂è', '‡∂ê', '‡∂ë', '‡∂í', '‡∂ì', '‡∂î', '‡∂ï', '‡∂ñ',
    
    # All consonants (38)
    '‡∂ö', '‡∂õ', '‡∂ú', '‡∂ù', '‡∂û', '‡∂ü', '‡∂†', '‡∂°', '‡∂¢', '‡∂£', '‡∂§', '‡∂•', '‡∂ß', '‡∂®', '‡∂©', '‡∂™', '‡∂´', '‡∂¨',
    '‡∂≠', '‡∂Æ', '‡∂Ø', '‡∂∞', '‡∂±', '‡∂≥', '‡∂¥', '‡∂µ', '‡∂∂', '‡∂∑', '‡∂∏', '‡∂π', '‡∂∫', '‡∂ª', '‡∂Ω', '‡∑Ä', '‡∑Å', '‡∑Ç', '‡∑É', '‡∑Ñ', '‡∑Ö', '‡∑Ü',
    
    # Vowel signs/diacritics when combined with consonants
    # ka combinations
    '‡∂ö‡∑è', '‡∂ö‡∑ê', '‡∂ö‡∑ë', '‡∂ö‡∑í', '‡∂ö‡∑ì', '‡∂ö‡∑î', '‡∂ö‡∑ñ', '‡∂ö‡∑ò', '‡∂ö‡∑ô', '‡∂ö‡∑ö', '‡∂ö‡∑õ', '‡∂ö‡∑ú', '‡∂ö‡∑ù', '‡∂ö‡∑û', '‡∂ö‡∑ä',
    
    # ga combinations
    '‡∂ú‡∑è', '‡∂ú‡∑ê', '‡∂ú‡∑ë', '‡∂ú‡∑í', '‡∂ú‡∑ì', '‡∂ú‡∑î', '‡∂ú‡∑ñ', '‡∂ú‡∑ò', '‡∂ú‡∑ô', '‡∂ú‡∑ö', '‡∂ú‡∑õ', '‡∂ú‡∑ú', '‡∂ú‡∑ù', '‡∂ú‡∑û', '‡∂ú‡∑ä',
    
    # ja combinations  
    '‡∂¢‡∑è', '‡∂¢‡∑ê', '‡∂¢‡∑ë', '‡∂¢‡∑í', '‡∂¢‡∑ì', '‡∂¢‡∑î', '‡∂¢‡∑ñ', '‡∂¢‡∑ò', '‡∂¢‡∑ô', '‡∂¢‡∑ö', '‡∂¢‡∑õ', '‡∂¢‡∑ú', '‡∂¢‡∑ù', '‡∂¢‡∑û', '‡∂¢‡∑ä',
    
    # ta combinations
    '‡∂≠‡∑è', '‡∂≠‡∑ê', '‡∂≠‡∑ë', '‡∂≠‡∑í', '‡∂≠‡∑ì', '‡∂≠‡∑î', '‡∂≠‡∑ñ', '‡∂≠‡∑ò', '‡∂≠‡∑ô', '‡∂≠‡∑ö', '‡∂≠‡∑õ', '‡∂≠‡∑ú', '‡∂≠‡∑ù', '‡∂≠‡∑û', '‡∂≠‡∑ä',
    
    # na combinations
    '‡∂±‡∑è', '‡∂±‡∑ê', '‡∂±‡∑ë', '‡∂±‡∑í', '‡∂±‡∑ì', '‡∂±‡∑î', '‡∂±‡∑ñ', '‡∂±‡∑ò', '‡∂±‡∑ô', '‡∂±‡∑ö', '‡∂±‡∑õ', '‡∂±‡∑ú', '‡∂±‡∑ù', '‡∂±‡∑û', '‡∂±‡∑ä',
    
    # pa combinations
    '‡∂¥‡∑è', '‡∂¥‡∑ê', '‡∂¥‡∑ë', '‡∂¥‡∑í', '‡∂¥‡∑ì', '‡∂¥‡∑î', '‡∂¥‡∑ñ', '‡∂¥‡∑ò', '‡∂¥‡∑ô', '‡∂¥‡∑ö', '‡∂¥‡∑õ', '‡∂¥‡∑ú', '‡∂¥‡∑ù', '‡∂¥‡∑û', '‡∂¥‡∑ä',
    
    # ma combinations
    '‡∂∏‡∑è', '‡∂∏‡∑ê', '‡∂∏‡∑ë', '‡∂∏‡∑í', '‡∂∏‡∑ì', '‡∂∏‡∑î', '‡∂∏‡∑ñ', '‡∂∏‡∑ò', '‡∂∏‡∑ô', '‡∂∏‡∑ö', '‡∂∏‡∑õ', '‡∂∏‡∑ú', '‡∂∏‡∑ù', '‡∂∏‡∑û', '‡∂∏‡∑ä',
    
    # ya combinations
    '‡∂∫‡∑è', '‡∂∫‡∑ê', '‡∂∫‡∑ë', '‡∂∫‡∑í', '‡∂∫‡∑ì', '‡∂∫‡∑î', '‡∂∫‡∑ñ', '‡∂∫‡∑ò', '‡∂∫‡∑ô', '‡∂∫‡∑ö', '‡∂∫‡∑õ', '‡∂∫‡∑ú', '‡∂∫‡∑ù', '‡∂∫‡∑û', '‡∂∫‡∑ä',
    
    # ra combinations
    '‡∂ª‡∑è', '‡∂ª‡∑ê', '‡∂ª‡∑ë', '‡∂ª‡∑í', '‡∂ª‡∑ì', '‡∂ª‡∑î', '‡∂ª‡∑ñ', '‡∂ª‡∑ò', '‡∂ª‡∑ô', '‡∂ª‡∑ö', '‡∂ª‡∑õ', '‡∂ª‡∑ú', '‡∂ª‡∑ù', '‡∂ª‡∑û', '‡∂ª‡∑ä',
    
    # la combinations
    '‡∂Ω‡∑è', '‡∂Ω‡∑ê', '‡∂Ω‡∑ë', '‡∂Ω‡∑í', '‡∂Ω‡∑ì', '‡∂Ω‡∑î', '‡∂Ω‡∑ñ', '‡∂Ω‡∑ò', '‡∂Ω‡∑ô', '‡∂Ω‡∑ö', '‡∂Ω‡∑õ', '‡∂Ω‡∑ú', '‡∂Ω‡∑ù', '‡∂Ω‡∑û', '‡∂Ω‡∑ä',
    
    # va combinations
    '‡∑Ä‡∑è', '‡∑Ä‡∑ê', '‡∑Ä‡∑ë', '‡∑Ä‡∑í', '‡∑Ä‡∑ì', '‡∑Ä‡∑î', '‡∑Ä‡∑ñ', '‡∑Ä‡∑ò', '‡∑Ä‡∑ô', '‡∑Ä‡∑ö', '‡∑Ä‡∑õ', '‡∑Ä‡∑ú', '‡∑Ä‡∑ù', '‡∑Ä‡∑û', '‡∑Ä‡∑ä',
    
    # sa combinations
    '‡∑É‡∑è', '‡∑É‡∑ê', '‡∑É‡∑ë', '‡∑É‡∑í', '‡∑É‡∑ì', '‡∑É‡∑î', '‡∑É‡∑ñ', '‡∑É‡∑ò', '‡∑É‡∑ô', '‡∑É‡∑ö', '‡∑É‡∑õ', '‡∑É‡∑ú', '‡∑É‡∑ù', '‡∑É‡∑û', '‡∑É‡∑ä',
    
    # ha combinations
    '‡∑Ñ‡∑è', '‡∑Ñ‡∑ê', '‡∑Ñ‡∑ë', '‡∑Ñ‡∑í', '‡∑Ñ‡∑ì', '‡∑Ñ‡∑î', '‡∑Ñ‡∑ñ', '‡∑Ñ‡∑ò', '‡∑Ñ‡∑ô', '‡∑Ñ‡∑ö', '‡∑Ñ‡∑õ', '‡∑Ñ‡∑ú', '‡∑Ñ‡∑ù', '‡∑Ñ‡∑û', '‡∑Ñ‡∑ä',
    
    # da combinations
    '‡∂Ø‡∑è', '‡∂Ø‡∑ê', '‡∂Ø‡∑ë', '‡∂Ø‡∑í', '‡∂Ø‡∑ì', '‡∂Ø‡∑î', '‡∂Ø‡∑ñ', '‡∂Ø‡∑ò', '‡∂Ø‡∑ô', '‡∂Ø‡∑ö', '‡∂Ø‡∑õ', '‡∂Ø‡∑ú', '‡∂Ø‡∑ù', '‡∂Ø‡∑û', '‡∂Ø‡∑ä',
    
    # ba combinations
    '‡∂∂‡∑è', '‡∂∂‡∑ê', '‡∂∂‡∑ë', '‡∂∂‡∑í', '‡∂∂‡∑ì', '‡∂∂‡∑î', '‡∂∂‡∑ñ', '‡∂∂‡∑ò', '‡∂∂‡∑ô', '‡∂∂‡∑ö', '‡∂∂‡∑õ', '‡∂∂‡∑ú', '‡∂∂‡∑ù', '‡∂∂‡∑û', '‡∂∂‡∑ä',
    
    # Additional important consonant combinations
    '‡∂†‡∑è', '‡∂†‡∑ê', '‡∂†‡∑ë', '‡∂†‡∑í', '‡∂†‡∑ì', '‡∂†‡∑î', '‡∂†‡∑ñ', '‡∂†‡∑ò', '‡∂†‡∑ô', '‡∂†‡∑ö', '‡∂†‡∑õ', '‡∂†‡∑ú', '‡∂†‡∑ù', '‡∂†‡∑û', '‡∂†‡∑ä',
    '‡∂∞‡∑è', '‡∂∞‡∑ê', '‡∂∞‡∑ë', '‡∂∞‡∑í', '‡∂∞‡∑ì', '‡∂∞‡∑î', '‡∂∞‡∑ñ', '‡∂∞‡∑ò', '‡∂∞‡∑ô', '‡∂∞‡∑ö', '‡∂∞‡∑õ', '‡∂∞‡∑ú', '‡∂∞‡∑ù', '‡∂∞‡∑û', '‡∂∞‡∑ä',
    '‡∂µ‡∑è', '‡∂µ‡∑ê', '‡∂µ‡∑ë', '‡∂µ‡∑í', '‡∂µ‡∑ì', '‡∂µ‡∑î', '‡∂µ‡∑ñ', '‡∂µ‡∑ò', '‡∂µ‡∑ô', '‡∂µ‡∑ö', '‡∂µ‡∑õ', '‡∂µ‡∑ú', '‡∂µ‡∑ù', '‡∂µ‡∑û', '‡∂µ‡∑ä',
    '‡∑Å‡∑è', '‡∑Å‡∑ê', '‡∑Å‡∑ë', '‡∑Å‡∑í', '‡∑Å‡∑ì', '‡∑Å‡∑î', '‡∑Å‡∑ñ', '‡∑Å‡∑ò', '‡∑Å‡∑ô', '‡∑Å‡∑ö', '‡∑Å‡∑õ', '‡∑Å‡∑ú', '‡∑Å‡∑ù', '‡∑Å‡∑û', '‡∑Å‡∑ä',
    
    # Sinhala numerals (10)
    '‡∑¶', '‡∑ß', '‡∑®', '‡∑©', '‡∑™', '‡∑´', '‡∑¨', '‡∑≠', '‡∑Æ', '‡∑Ø',
    
    # Common conjunct consonants and special characters
    '‡∂ö‡∑ä‡∂ª', '‡∂ú‡∑ä‡∂ª', '‡∂≠‡∑ä‡∂ª', '‡∂¥‡∑ä‡∂ª', '‡∑Å‡∑ä‡∂ª', '‡∂ö‡∑ä‡∑Ä', '‡∂ú‡∑ä‡∑Ä', '‡∂Ø‡∑ä‡∑Ä', '‡∂≠‡∑ä‡∑Ä', '‡∂±‡∑ä‡∂Ø', '‡∂±‡∑ä‡∂≠', '‡∂∏‡∑ä‡∂¥', '‡∂∫‡∑ä‡∂∫', '‡∂Ω‡∑ä‡∂Ω',
    
    # Special marks and symbols
    '‡∑ä', '‡∂Ç', '‡∂É', '‡∑¥'
]

def generate_complete_dataset():
    """Generate the most comprehensive Sinhala dataset possible."""
    from PIL import Image, ImageDraw, ImageFont
    import random
    
    dataset_dir = "sinhala_complete_dataset"
    if not os.path.exists(dataset_dir):
        os.makedirs(dataset_dir)
    
    # Load Sinhala font
    try:
        font_large = ImageFont.truetype("NotoSansSinhala-Regular.ttf", 56)  # Larger for clarity
        font_medium = ImageFont.truetype("NotoSansSinhala-Regular.ttf", 48)
        font_small = ImageFont.truetype("NotoSansSinhala-Regular.ttf", 42)
        fonts = [font_large, font_medium, font_small]
    except:
        print("‚ùå Font not found, using default font")
        fonts = [ImageFont.load_default()]
    
    print(f"üî• Generating COMPLETE Sinhala dataset for {len(COMPLETE_SINHALA_CHARS)} characters...")
    
    samples_per_char = 80  # More samples for better accuracy
    
    for i, char in enumerate(COMPLETE_SINHALA_CHARS):
        char_dir = os.path.join(dataset_dir, char.replace('/', '_'))  # Handle special chars
        if not os.path.exists(char_dir):
            os.makedirs(char_dir)
        
        print(f"Generating {i+1}/{len(COMPLETE_SINHALA_CHARS)}: {char}")
        
        for j in range(samples_per_char):
            # Create image with variation
            img_size = random.choice([64, 68, 72])  # Size variation
            img = Image.new('RGB', (img_size, img_size), color='white')
            draw = ImageDraw.Draw(img)
            
            # Add variation
            x_offset = random.randint(-4, 4)
            y_offset = random.randint(-4, 4)
            font = random.choice(fonts)
            
            # Random rotation (small angle)
            if random.random() < 0.3:  # 30% chance of slight rotation
                angle = random.randint(-5, 5)
                img = img.rotate(angle, fillcolor='white')
                draw = ImageDraw.Draw(img)
            
            # Draw character
            try:
                # Get text bbox for centering
                bbox = draw.textbbox((0, 0), char, font=font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
                
                # Center the text
                x = (img_size - text_width) // 2 + x_offset
                y = (img_size - text_height) // 2 + y_offset
                
                # Random color variation (very dark grays to black)
                color_intensity = random.randint(0, 30)  # Very dark
                color = (color_intensity, color_intensity, color_intensity)
                
                draw.text((x, y), char, font=font, fill=color)
            except Exception as e:
                # Fallback to simple positioning
                draw.text((8 + x_offset, 12 + y_offset), char, font=font, fill='black')
            
            # Add slight noise occasionally
            if random.random() < 0.1:  # 10% chance
                for _ in range(random.randint(1, 3)):
                    noise_x = random.randint(0, img_size-1)
                    noise_y = random.randint(0, img_size-1)
                    draw.point((noise_x, noise_y), fill='gray')
            
            # Resize to standard 64x64
            img = img.resize((64, 64), Image.LANCZOS)
            
            # Save image
            img_path = os.path.join(char_dir, f"{char.replace('/', '_')}_{j:03d}.png")
            img.save(img_path)
    
    return dataset_dir

def create_complete_model(num_classes):
    """Create a robust CNN model for complete character set."""
    model = Sequential([
        # First convolutional block
        Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 1), padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # Second convolutional block
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # Third convolutional block
        Conv2D(256, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.25),
        
        # Fourth convolutional block - for complex character recognition
        Conv2D(512, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D((2, 2)),
        Dropout(0.3),
        
        # Flatten and dense layers
        Flatten(),
        Dense(1024, activation='relu'),
        Dropout(0.5),
        Dense(512, activation='relu'),
        Dropout(0.4),
        Dense(256, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    
    return model

def train_complete_model():
    """Train the complete Sinhala character recognition model."""
    print("üöÄ Complete Sinhala OCR Training Starting...")
    print(f"üìä Target: {len(COMPLETE_SINHALA_CHARS)} characters")
    
    # Generate dataset
    dataset_dir = generate_complete_dataset()
    
    print("üìä Loading and preprocessing complete dataset...")
    X, y, labels = make_dataset_arrays(dataset_dir, 64)
    
    print(f"‚úÖ Complete dataset loaded: {X.shape[0]} samples, {len(labels)} classes")
    print(f"üìù Total characters: {len(labels)}")
    print(f"üìù Sample characters: {labels[:15]}")
    
    # Create and compile model
    model = create_complete_model(len(labels))
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("üèóÔ∏è Complete Model Architecture:")
    model.summary()
    
    # Callbacks
    early_stopping = EarlyStopping(
        monitor='val_accuracy',
        patience=8,
        restore_best_weights=True,
        verbose=1
    )
    
    reduce_lr = ReduceLROnPlateau(
        monitor='val_accuracy',
        factor=0.2,
        patience=4,
        min_lr=0.00001,
        verbose=1
    )
    
    # Train model
    print("üéì Training complete model...")
    history = model.fit(
        X, y,
        batch_size=64,  # Larger batch for stability
        epochs=50,      # More epochs for complex dataset
        validation_split=0.2,
        callbacks=[early_stopping, reduce_lr],
        verbose=1
    )
    
    # Save model
    model_path = "sinhala_complete_cnn.h5"
    model.save(model_path)
    print(f"üíæ Complete model saved as: {model_path}")
    
    # Save labels
    labels_path = "sinhala_complete_cnn.h5.labels.json"
    with open(labels_path, 'w', encoding='utf-8') as f:
        json.dump(labels, f, ensure_ascii=False, indent=2)
    print(f"üè∑Ô∏è Complete labels saved as: {labels_path}")
    
    # Evaluate final performance
    final_accuracy = max(history.history['val_accuracy'])
    print(f"üéØ Best Validation Accuracy: {final_accuracy:.4f}")
    
    print(f"\nüéä COMPLETE SINHALA CHARACTER SET TRAINED!")
    print(f"üìä Total Characters: {len(labels)}")
    print(f"üéØ Model ready for ALL Sinhala text recognition!")
    
    return True

if __name__ == "__main__":
    print("üî§ Complete Sinhala OCR Training System")
    print("=" * 60)
    print(f"üéØ Training {len(COMPLETE_SINHALA_CHARS)} Sinhala characters")
    print("=" * 60)
    
    if train_complete_model():
        print("\nüéâ COMPLETE TRAINING FINISHED!")
        print("‚úÖ All major Sinhala characters now supported")
        print("üîÑ Update your OCR application to use: sinhala_complete_cnn.h5")
        print("üìù This model can recognize the full Sinhala Unicode character set!")
    else:
        print("\n‚ùå Training failed!")